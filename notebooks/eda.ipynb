{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.vision.all import *\n",
    "import torch.nn.functional as nnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cuda0 = torch.device('cuda:0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_path = Path('Z:\\cloud\\data\\hpa-single-cell-image-classification')\n",
    "path = Path('../data')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path/'train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = [str(i) for i in range(19)]\n",
    "for x in labels:\n",
    "    df[x] = df['Label'].apply(lambda r: int(x in r.split('|')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfs_0 = df[df['Label'] == '0'].sample(n=300, random_state=42).reset_index(drop=True)\n",
    "dfs_1 = df[df['1'] == 1].sample(n=400, random_state=42).reset_index(drop=True)\n",
    "dfs_1u = df[df['Label'] == '1'].sample(n=221, random_state=42).reset_index(drop=True)\n",
    "dfs_2 = df[df['Label'] == '2'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_3 = df[df['Label'] == '3'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_4 = df[df['Label'] == '4'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_5 = df[df['Label'] == '5'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_6 = df[df['6'] == 1].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_7 = df[df['Label'] == '7'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_8 = df[df['Label'] == '8'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_9 = df[df['9'] == 1].sample(n=400, random_state=42).reset_index(drop=True)\n",
    "dfs_9u = df[df['Label'] == '9'].sample(n=200, random_state=42).reset_index(drop=True)\n",
    "dfs_10 = df[df['10'] == 1].sample(n=400, random_state=42).reset_index(drop=True)\n",
    "dfs_10u = df[df['Label'] == '10'].sample(n=200, random_state=42).reset_index(drop=True)\n",
    "dfs_11 = df[df['11'] == 1].reset_index(drop=True)\n",
    "dfs_12 = df[df['Label'] == '12'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_13 = df[df['Label'] == '13'].sample(n=400, random_state=42).reset_index(drop=True)\n",
    "dfs_14 = df[df['Label'] == '14'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_15 = df[df['15'] == 1].reset_index(drop=True)\n",
    "dfs_16 = df[df['Label'] == '16'].sample(n=350, random_state=42).reset_index(drop=True)\n",
    "dfs_17 = df[df['17'] == 1].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_18 = df[df['18'] == 1].reset_index(drop=True)\n",
    "dfs_ = [dfs_0, dfs_1, dfs_1u, dfs_2, dfs_3, dfs_4, dfs_5, dfs_6, dfs_7, dfs_8, dfs_9, dfs_9u, dfs_10, dfs_10u,\n",
    "        dfs_11, dfs_12, dfs_13, dfs_14, dfs_15, dfs_16, dfs_17, dfs_18]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfs = pd.concat(dfs_, ignore_index=True)\n",
    "dfs.drop_duplicates(inplace=True, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_img(image_id: str, color: str, image_size: int):\n",
    "    filename=f'{data_path}/train/{image_id}_{color}.png'\n",
    "    img = Image.open(filename)\n",
    "\n",
    "    size = (image_size, image_size)\n",
    "\n",
    "    img = allPil2tensor2(img).to(cuda0)\n",
    "\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.float()\n",
    "    img = nnf.interpolate(img, size=size, mode='bilinear', align_corners=False)\n",
    "    img = img.type(torch.uint8)\n",
    "    img = img[0,:,:,:]\n",
    "\n",
    "    return img\n",
    "\n",
    "def allPil2tensor2(image: Image.Image)->TensorImage:\n",
    "    arr = np.asarray(image)\n",
    "\n",
    "    if arr.ndim==2 : arr = np.expand_dims(arr,2)\n",
    "\n",
    "    # Transpose width, height to height,width\n",
    "    arr = np.transpose(arr, (1,0,2))\n",
    "\n",
    "    # Move channels to the first position\n",
    "    arr = np.transpose(arr, (2, 1, 0))\n",
    "\n",
    "    return torch.from_numpy(arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_samples(image_size: int):\n",
    "    all_cells = []\n",
    "    num_files = len(dfs)\n",
    "\n",
    "    for idx in tqdm(range(num_files)):\n",
    "        image_id = dfs.iloc[idx].ID\n",
    "        labels = dfs.iloc[idx].Label\n",
    "        red = read_img(image_id, \"red\", image_size)\n",
    "        green = read_img(image_id, \"green\", image_size)\n",
    "        blue = read_img(image_id, \"blue\", image_size)\n",
    "\n",
    "        stacked_image = torch.stack([blue, green, red], axis=1)\n",
    "        stacked_image = stacked_image[0,:,:,:]\n",
    "\n",
    "        stacked_image = torch.transpose(stacked_image, dim0=2, dim1=0)\n",
    "\n",
    "        fname = f'{image_id}.jpg'\n",
    "\n",
    "        arr = stacked_image.cpu().numpy()\n",
    "        im = Image.fromarray(arr, \"RGB\")\n",
    "        torch\n",
    "\n",
    "        im.save(path/f'train/{fname}', format=\"JPEG\")\n",
    "\n",
    "        all_cells.append({\n",
    "            'image_id': image_id,\n",
    "            'image_labels': labels\n",
    "        })\n",
    "\n",
    "    cell_df = pd.DataFrame(all_cells)\n",
    "    cell_df.to_csv(path/'cell_df.csv', index=False)\n",
    "    print(cell_df.head())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_samples(460)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}