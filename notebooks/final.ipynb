{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Week 9\n",
    "> Week 9 exercises.\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [jupyter, exercise]\n",
    "- image: images/chart-preview.png"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Group Members:\n",
    "- Johannes Ehlers Nyholm Thomsen\n",
    "- Kaare Veggerby Sandbøl\n",
    "- Kasper Malmsiø Hoffmann\n",
    "- Mike Holst Meldgaard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.vision.all import *\n",
    "import torch.nn.functional as nnf\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from fastai.callback.all import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scclib.util.image import create_samples, assemble_rgb_image, get_rgb_pieces_tensors, HPAImage"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collect data:\n",
    "Vores data, som er udleveret fra Kaggle, skal vi have samlet i det udleverede data til en kanal.\n",
    "Et billede er udleveret som 4 greyscaled billeder,\n",
    "hvor hvert greyscaled billede repræsenterer rød, grøn, blå og gul farve af det samlede billede.\n",
    "\n",
    "I denne konkurrences forum har folk konkluderet, at den gule del af billedet har ingen indflydelse på modellernes præcision, hvorfor vi har valgt at sortere den fra.\n",
    "\n",
    "Vi skal derfor have samlet de 3 RBG billeder til et samlet billede.\n",
    "Til at gøre dette har vi lavet et hjælpe bibliotek, da det bare er en masse python kode.\n",
    "Koden tager de 3 billeder, putter deres data i den respektive farve kanal for et samlet billede og resizer til en ønsket størrelse.\n",
    "Vi resizer allerede her, da vi så kan gøre det på GPU i stedet for CPU'en."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cuda0 = torch.device('cuda:0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_path = Path('Z:\\cloud\\data\\hpa-single-cell-image-classification')\n",
    "path = Path('../data')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path/'train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = [str(i) for i in range(19)]\n",
    "for x in labels:\n",
    "    df[x] = df['Label'].apply(lambda r: int(x in r.split('|')))\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfs_0 = df[df['Label'] == '0'].sample(n=300, random_state=42).reset_index(drop=True)\n",
    "dfs_1 = df[df['1'] == 1].sample(n=400, random_state=42).reset_index(drop=True)\n",
    "dfs_1u = df[df['Label'] == '1'].sample(n=221, random_state=42).reset_index(drop=True)\n",
    "dfs_2 = df[df['Label'] == '2'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_3 = df[df['Label'] == '3'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_4 = df[df['Label'] == '4'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_5 = df[df['Label'] == '5'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_6 = df[df['6'] == 1].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_7 = df[df['Label'] == '7'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_8 = df[df['Label'] == '8'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_9 = df[df['9'] == 1].sample(n=400, random_state=42).reset_index(drop=True)\n",
    "dfs_9u = df[df['Label'] == '9'].sample(n=200, random_state=42).reset_index(drop=True)\n",
    "dfs_10 = df[df['10'] == 1].sample(n=400, random_state=42).reset_index(drop=True)\n",
    "dfs_10u = df[df['Label'] == '10'].sample(n=200, random_state=42).reset_index(drop=True)\n",
    "dfs_11 = df[df['11'] == 1].reset_index(drop=True)\n",
    "dfs_12 = df[df['Label'] == '12'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_13 = df[df['Label'] == '13'].sample(n=400, random_state=42).reset_index(drop=True)\n",
    "dfs_14 = df[df['Label'] == '14'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_15 = df[df['15'] == 1].reset_index(drop=True)\n",
    "dfs_16 = df[df['Label'] == '16'].sample(n=350, random_state=42).reset_index(drop=True)\n",
    "dfs_17 = df[df['17'] == 1].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_18 = df[df['18'] == 1].reset_index(drop=True)\n",
    "dfs_ = [dfs_0, dfs_1, dfs_1u, dfs_2, dfs_3, dfs_4, dfs_5, dfs_6, dfs_7, dfs_8, dfs_9, dfs_9u, dfs_10, dfs_10u,\n",
    "        dfs_11, dfs_12, dfs_13, dfs_14, dfs_15, dfs_16, dfs_17, dfs_18]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfs = pd.concat(dfs_, ignore_index=True)\n",
    "dfs.drop_duplicates(inplace=True, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_path = Path('../data')\n",
    "\n",
    "image_path = Path('Z:/cloud/data/hpa-single-cell-image-classification/train')\n",
    "image_destination = data_path/'train'\n",
    "\n",
    "if not image_destination.exists():\n",
    "    os.makedirs(image_destination)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "example_image = image_path.ls()[0].name\n",
    "image_id, image_ext = example_image.split('.')\n",
    "\n",
    "image_id = image_id.split('_')[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation:\n",
    "Billederne bliver udleveret i en kvalitet af 1080p og op efter.\n",
    "Vi har valgt at resize dem til 512 gange 512 for at bevare nok billede kvalitet men også undgå at løbe tør for hukkomelse på computeren.\n",
    "\n",
    "Efter vi har fundet dataen skal vi have loaded dem ind i en dataloader.\n",
    "Samtidig med at vi gør det cropper vi også billederne ned til 256 gange 256 opløsning,\n",
    "og da vi bruger batch_tfms sker der en tilfældig crop og augmentering.\n",
    "Der sker dog kun resizing på valideringssettet.\n",
    "\n",
    "Vi har altså været nød til selv manuelt at implementere den fremgangsmåde,\n",
    "som fastai kalder presizing, da vores udleverede billeder er i så høj kvalitet.\n",
    "Vi interpolerer dog 2 gange i stedet for kun én gang, som hvis vi brugte fastai presizing,\n",
    "hvilket resulterer i en ringere billedkvalitet, men vi vinder performance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_img = HPAImage(id=image_id,\n",
    "                   ext=image_ext,\n",
    "                   path=image_path,\n",
    "                   device=\"cuda:0\",\n",
    "                   size=512)\n",
    "\n",
    "new_img.plot_all()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "create_samples(512, dfs, image_path, image_destination, csv_path=data_path/'cells_sample.csv', device=\"cuda:0\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_path = Path('../models')\n",
    "path = Path('../data')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cell_df = pd.read_csv(path/'cells_sample.csv')\n",
    "cell_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_x(r): return path/'train'/f\"{r['image_id']}.png\"\n",
    "def get_y(r): return r['image_labels'].split('|')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_dls(bs: int, size: int):\n",
    "    return DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n",
    "                     splitter=RandomSplitter(seed=42),\n",
    "                     get_x=get_x,\n",
    "                     get_y=get_y,\n",
    "                     batch_tfms=aug_transforms(size=size, min_scale=0.75))\\\n",
    "        .dataloaders(cell_df, bs=bs, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "image_size = 256\n",
    "\n",
    "dls = get_dls(batch_size, image_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Choose Model:\n",
    "Vi har valgt at bruge et residualt netværk, som er trænet på ImageNet.\n",
    "I vores model er det kun et netværk med 18 lag, så vi ikke skal vente hundrede år mellem hver træning,\n",
    "når vi eksperimenterer med modellen.\n",
    "Derudover så vi ikke en markant højere præcision, da vi trænede med modellen med 50 lag.\n",
    "Det kan også ses, at vi bruger fp16 for at spare regnekraft mens vi træner."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, metrics=partial(accuracy_multi, thresh=0.2)).to_fp16()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation:\n",
    "Til vores models metric bruger vi standard præcision for multicategory, hvilket er accuracy_multi.\n",
    "Vi vil dog gerne have en threshhold på 0.2, derfor er vi nød til at give mertics en partial,\n",
    "hvilket betyder at der laves en ny version af accuracy_multi, hvor threshold er den værdi vi sender med i partial.\n",
    "\n",
    "## Tuning:\n",
    "Da vi har valgt at bruge en på-forhånd trænet model, ResNet, er vi nød til at finjustere den til vores problem.\n",
    "Dette gøres ved at kalde fine_tune på vores learner.\n",
    "fine_tune smider det sidste linære lag i modellen væk og skifter det ud med et nyt linært lag.\n",
    "Dernæst fryser modellen vægtene i alle de gamle lag, og træner nu det nye linære lag i en epoche.\n",
    "Derefter tøes de frosne lag op og modellen trænes nu sammen i det ønskede antal gange - her er det 5.\n",
    "\n",
    "På denne måde undgår vi at smide alt den træning modellen har fra ImageNet væk,\n",
    "og modellen bliver stadig optimeret til lige vores problemstilling."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with learn.no_bar():\n",
    "    learn.fine_tune(5, base_lr=0.03)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Hook:\n",
    "    def hook_func(self, model, input, output):\n",
    "        self.stored = output.detach().clone()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hook_output = Hook()\n",
    "hook = learn.model[0].register_forward_hook(hook_output.hook_func)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad(): output = learn.model.eval()(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "act = hook_output.stored[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "F.softmax(output, dim=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dls.vocab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cam_map = torch.einsum('ck,kij->cij', learn.model[1][-1].weight, act)\n",
    "cam_map.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cam_map[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = dls.one_batch()[0][0].unsqueeze(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_dec = TensorImage(dls.train.decode((x,))[0][0])\n",
    "_,ax = plt.subplots()\n",
    "x_dec.show(ctx=ax)\n",
    "ax.imshow(cam_map[1].detach().cpu(), alpha=0.5, extent=(0,256,256,0), interpolation='bilinear', cmap='nipy_spectral')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = Path('Z:/cloud/data/hpa-single-cell-image-classification/test')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images = get_images_files(path)\n",
    "images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction:\n",
    "Vi har ikke kunnet få Kaggle til at give os en score på vores model,\n",
    "da de vil vores predictions i en meget speciel og træls opsætning."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dl = learn.dls.test.test_dl(images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with learn.no_bar():\n",
    "    predictions, _ = learn.predict(dl=test_dl)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}